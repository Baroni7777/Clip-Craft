import os
import shutil
import time
import json
import re
import requests
from urllib.parse import quote, urlparse
from dotenv import load_dotenv

import streamlit as st
from video_helpers import *
from moviepy.config import change_settings
import google.generativeai as genai
import google.cloud.texttospeech as tts


load_dotenv()
change_settings(
    {"IMAGEMAGICK_BINARY": r"C:\\Program Files\\ImageMagick-7.1.1-Q16\\magick.exe"}
)
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

PEXEL_HEADERS = {"Authorization": os.getenv("PEXEL_API_KEY")}
VID_PREF = "https://api.pexels.com/videos/search?"
IMG_PREF = "https://api.pexels.com/v1/search?"


with open("format/example.json", "r") as file:
    example = json.load(file)

with open("format/config.json", "r") as file:
    config = json.load(file)

SYSTEM_MESSAGE = f"""
You are an AI content creator. You have been tasked to provide narration to video contents.

The user will provide the title, description, content type and duration of the final video. 
Attach is a list of media files, with descriptions generated by AI based on the media content.

You have to generate a script for each clip, and feel free to rearrange clips to form a coherent content.
You have integration with Pexel API and can add stock footage in between to make the content more engaging.
You must use all the media files provided by the user. And include some stock footage in between clips.

Choose the best transition that fits in well between clips, and you may insert text on-scene if it helps.
Always choose a suitable background music for the video.

As your response, write in this structured JSON format: \n {example}
Note the values above is just an example, Enclose property names in double quotes.
Here are some input options you can use: \n {config}
"""


video_model = genai.GenerativeModel(
    "gemini-1.5-flash", system_instruction=SYSTEM_MESSAGE
)
desc_model = genai.GenerativeModel("gemini-1.5-flash")


def upload_img(img_path):
    img_file = genai.upload_file(img_path)
    img_file = genai.get_file(img_file.name)
    return img_file


def upload_vid(vid_path):
    vid_file = genai.upload_file(vid_path)
    while vid_file.state.name == "PROCESSING":
        print(".", end="")
        time.sleep(2)
        vid_file = genai.get_file(vid_file.name)

    if vid_file.state.name == "FAILED":
        raise ValueError(vid_file.state.name)
    else:
        return vid_file


def query_pexel(url):
    response = requests.get(url, headers=PEXEL_HEADERS)
    response.raise_for_status()

    return response.json()


def download_stock(media_url):
    response = requests.get(media_url)
    response.raise_for_status()

    parsed_url = urlparse(media_url)
    filename = os.path.basename(parsed_url.path)
    file_path = os.path.join(r"temp\media", filename)

    with open(file_path, "wb") as file:
        file.write(response.content)

    return file_path


def text_to_speech(text, out_name):
    text_input = tts.SynthesisInput(text=text)
    voice_params = tts.VoiceSelectionParams(
        language_code="en-US", name="en-US-Studio-O"
    )
    audio_config = tts.AudioConfig(audio_encoding=tts.AudioEncoding.LINEAR16)

    client = tts.TextToSpeechClient(
        client_options={"api_key": os.getenv("GCLOUD_API_KEY")}
    )
    response = client.synthesize_speech(
        input=text_input,
        voice=voice_params,
        audio_config=audio_config,
    )

    file_path = os.path.join(r"temp\audio", f"{out_name}.wav")
    with open(file_path, "wb") as out:
        out.write(response.audio_content)
        print(f'Generated speech saved to "{file_path}"')

    return file_path


def format_json(raw):
    match = re.search(r"```json(.*?)```", raw, re.DOTALL)
    if match:
        text = match.group(1).strip()
        return json.loads(text)
    return None


st.title("AI Video Script Generator")

title = st.text_input("Title")
desc = st.text_area("Description")
style = st.selectbox("Style", ["promotional", "educational", "travel"])
duration = st.slider("Duration (seconds)", min_value=1, max_value=60)
orient = st.selectbox("Orientation", ["landscape", "portrait"])

uploaded_files = st.file_uploader(
    "Upload Media Files", accept_multiple_files=True, type=["jpg", "mp4"]
)

if st.button("Generate Script"):
    if not title or not desc or not duration or not uploaded_files:
        st.error("Please fill in all fields and upload media files.")
    else:
        if not os.path.exists("temp"):
            os.makedirs(r"temp\media")
            os.makedirs(r"temp\audio")

        if orient == "portrait":
            res = (720, 1280)
        else:
            res = (1280, 720)

        
        media_data = []
        with st.spinner("Analyzing your media..."):
            for file in uploaded_files:
                file_path = os.path.join(r"temp\media", file.name)
                with open(file_path, "wb") as f:
                    f.write(file.getbuffer())

                if file_path.endswith(".jpg"):
                    prompt = "write a short one-sentence description for the image"
                    file_obj = upload_img(file_path)
                elif file_path.endswith(".mp4"):
                    prompt = "write a short one-paragraph description for the video, depending on its duration."
                    file_obj = upload_vid(file_path)

                response = desc_model.generate_content([file_obj, prompt])
                genai.delete_file(file_obj.name)

                media_data.append({"source": file_path, "desc": response.text})

        video_prompt = f"""title: {title} description: {desc} style: {style} duration: {duration}
        Media clips and AI descriptions: {media_data}
        """
        with st.spinner("Generating script..."):
            response = video_model.generate_content(video_prompt)
            print(response.text)

        script = format_json(response.text)
        with st.spinner("Downloading stock footage..."):
            for clip in script["scenes"]:
                source, form = clip["type"].split("_")
                if source == "stock":
                    suffix = f"query={quote(clip['query'])}&per_page=1"

                    if form == "video":
                        response = query_pexel(VID_PREF + suffix)
                        media_url = response["videos"][0]["video_files"][0]["link"]
                        file_path = download_stock(media_url)

                    elif form == "photo":
                        response = query_pexel(IMG_PREF + suffix)
                        media_url = response["photos"][0]["src"]["landscape"]
                        file_path = download_stock(media_url)

                    clip["media_path"] = file_path
                    del clip["query"]

        with st.spinner("Generating narration.."):
            for clip in script["scenes"]:
                file_name = os.path.splitext(os.path.basename(clip["media_path"]))[0]
                text = clip["script"]
                audio_path = text_to_speech(text, file_name)
                clip["audio_path"] = audio_path
                del clip["script"]


        st.subheader("Video Script")
        st.json(script)

        clips = []
        with st.spinner("Creating final video..."):
            music_file = os.path.join("music", script["music"] + ".mp3")
            for i, pair in enumerate(script["scenes"]):
                form = pair["type"].split("_")[1]
                if form == "photo":
                    clip = create_photo_clip(pair["media_path"], pair["audio_path"], res)
                elif form == "video":
                    clip = create_video_clip(pair["media_path"], pair["audio_path"], res)

                if pair["text_overlay"]:
                    clip = add_text_overlay(clip, pair["text_overlay"])

                # if i > 0:
                #     prev_clip = clips[-1]
                #     transition_type = script["scenes"][i - 1].get("transition", "fade")
                #     prev_clip, clip = VideoTransitionHelper.apply_transition(
                #         prev_clip, clip, transition_type
                #     )
                #     clips[-1] = prev_clip

                clips.append(clip)

            final_clip = concatenate_videoclips(clips)
            final_clip = add_background_music(final_clip, music_file)
            final_clip.write_videofile(
                r"temp\final_video.mp4", codec="libx264", audio_codec="aac"
            )

            shutil.rmtree(r"temp\media", ignore_errors=True)
            shutil.rmtree(r"temp\audio", ignore_errors=True)

        st.video(r"temp\final_video.mp4")
