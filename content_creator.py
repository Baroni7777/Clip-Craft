import os
import shutil
import time
import json
import requests
from urllib.parse import quote, urlparse
from dotenv import load_dotenv

import streamlit as st
from moviepy.editor import *
import google.generativeai as genai
import google.cloud.texttospeech as tts



load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

PEXEL_HEADERS = {"Authorization": os.getenv("PEXEL_API_KEY")}
VID_PREF = "https://api.pexels.com/videos/search?"
IMG_PREF = "https://api.pexels.com/v1/search?"

SYSTEM_MESSAGE = """
You are an AI content creator. You have been tasked to provide narration to video contents.
The user will provide the title, description, style and duration of the final video. 
Attach is a list of media files, with descriptions generated by AI based on the media content.
You have to generate a script for each clip, and feel free to rearrange clips to form a coherent content.
You have integration with Pexel API and can add stock footage in between to make the content more engaging.
As your response, write in this structured format:
{
    "content": [
        {"type": "media_photo", "media_path": "./image1.jpg", "script": "We begin our journey with "},
        {"type": "media_video", "media_path": "./video1.mp4", "script": "As we move closer, "},
        {"type": "stock_photo", "query": "waterfall", "script": "In between, we transition to "},
        {"type": "stock_video", "query": "ocean", "script": "Our journey concludes with "},
    ]
}
"""

video_model = genai.GenerativeModel("gemini-1.5-flash", system_instruction=SYSTEM_MESSAGE)
desc_model = genai.GenerativeModel("gemini-1.5-flash")

def upload_img(img_path):
    img_file = genai.upload_file(img_path)
    img_file = genai.get_file(img_file.name)
    return img_file

def upload_vid(vid_path):
    vid_file = genai.upload_file(vid_path)
    while vid_file.state.name == "PROCESSING":
        print(".", end="")
        time.sleep(2)
        vid_file = genai.get_file(vid_file.name)

    if vid_file.state.name == "FAILED":
        raise ValueError(vid_file.state.name)
    else:
        return vid_file


def query_pexel(url):
    response = requests.get(url, headers=PEXEL_HEADERS)
    response.raise_for_status()

    return response.json()

def download_stock(media_url):
    response = requests.get(media_url)
    response.raise_for_status()

    parsed_url = urlparse(media_url)
    filename = os.path.basename(parsed_url.path)
    file_path = os.path.join(r"temp\media", filename)

    with open(file_path, "wb") as file:
        file.write(response.content)

    return file_path


def text_to_speech(text, out_name):
    text_input = tts.SynthesisInput(text=text)
    voice_params = tts.VoiceSelectionParams(
        language_code='en-US', name='en-US-Studio-O'
    )
    audio_config = tts.AudioConfig(audio_encoding=tts.AudioEncoding.LINEAR16)

    client = tts.TextToSpeechClient(
        client_options={"api_key": os.getenv("GCLOUD_API_KEY")}
    )
    response = client.synthesize_speech(
        input=text_input,
        voice=voice_params,
        audio_config=audio_config,
    )

    file_path = os.path.join(r'temp\audio', f"{out_name}.wav")
    with open(file_path, "wb") as out:
        out.write(response.audio_content)
        print(f'Generated speech saved to "{file_path}"')

    return file_path


def create_video_clip(video_path, audio_path):
    audio = AudioFileClip(audio_path)
    duration = audio.duration
    video = VideoFileClip(video_path).set_fps(25).resize((1280, 720))

    # video = video.margin(left=(1280 - video.size[0]) // 2,
    #                      right=(1280 - video.size[0]) // 2,
    #                      top=(720 - video.size[1]) // 2,
    #                      bottom=(720 - video.size[1]) // 2,
    #                      color=(0, 0, 0))

    if video.duration > duration:
        video = video.subclip(0, duration)
    elif video.duration < duration:
        repeats = int(duration // video.duration) + 1
        video = concatenate_videoclips([video] * repeats).subclip(0, duration)
        
    video = video.set_audio(audio)
    
    return video

def create_photo_clip(photo_path, audio_path):
    audio = AudioFileClip(audio_path)
    duration = audio.duration
    photo = ImageClip(photo_path).set_duration(duration).resize((1280, 720))

    # photo = photo.margin(left=(1280 - photo.size[0]) // 2,
    #                      right=(1280 - photo.size[0]) // 2,
    #                      top=(720 - photo.size[1]) // 2,
    #                      bottom=(720 - photo.size[1]) // 2,
    #                      color=(0, 0, 0))

    photo = photo.set_audio(audio)
    return photo



st.title("AI Video Script Generator")

title = st.text_input("Title")
desc = st.text_area("Description")
style = st.selectbox("Style", ["promotional", "informative", "documentary"])
duration = st.slider("Duration (seconds)", min_value=1, max_value=60)

uploaded_files = st.file_uploader("Upload Media Files", accept_multiple_files=True, type=["jpg", "mp4"])

if not os.path.exists("temp"):
    os.makedirs(r"temp\media")
    os.makedirs(r"temp\audio")

if st.button("Generate Script"):
    if not title or not desc or not duration or not uploaded_files:
        st.error("Please fill in all fields and upload media files.")
    else:
        media_data = []
        with st.spinner('Analyzing your media...'):
            for file in uploaded_files:
                file_path = os.path.join(r"temp\media", file.name)
                with open(file_path, "wb") as f:
                    f.write(file.getbuffer())

                if file_path.endswith(".jpg"):
                    prompt = 'write a short one-sentence description for the image'
                    file_obj = upload_img(file_path)
                elif file_path.endswith(".mp4"):
                    prompt = 'write a short one-paragraph description for the video, depending on its duration.'
                    file_obj = upload_vid(file_path)

                response = desc_model.generate_content([file_obj, prompt])
                genai.delete_file(file_obj.name)

                media_data.append({"source": file_path, "desc": response.text})


        video_prompt = f'''title: {title} description: {desc} style: {style} duration: {duration}
        Media clips and AI descriptions: {media_data}
        '''
        with st.spinner('Generating script...'):
            response = video_model.generate_content(video_prompt)
        
        script = json.loads(response.text)['content']
        with st.spinner('Downloading stock footage...'):
            for clip in script:
                source, form = clip['type'].split('_')
                if source == 'stock':
                    suffix = f"query={quote(clip['query'])}&per_page=1"

                    if form == "video":
                        response = query_pexel(VID_PREF + suffix)
                        media_url = response["videos"][0]["video_files"][0]["link"]
                        file_path = download_stock(media_url)

                    elif form == "photo":
                        response = query_pexel(IMG_PREF + suffix)
                        media_url = response["photos"][0]["src"]["landscape"]
                        file_path = download_stock(media_url)

                    clip['media_path'] = file_path
                    del clip['query']
        

        with st.spinner('Generating narration..'):
            for clip in script:
                file_name = os.path.splitext(os.path.basename(clip['media_path']))[0]
                text = clip['script']
                audio_path = text_to_speech(text, file_name)
                clip['audio_path'] = audio_path
                del clip['script']


        st.subheader("Video Script")
        st.json(script)

        clips = []
        with st.spinner('Creating final video...'):
            for pair in script:
                form = pair["type"].split('_')[1]
                if form == "photo":
                    clip = create_photo_clip(pair["media_path"], pair["audio_path"])
                elif form == "video":
                    clip = create_video_clip(pair["media_path"], pair["audio_path"])
                clips.append(clip)

            final_clip = concatenate_videoclips(clips)
            final_clip.write_videofile(r"temp\final_video.mp4", codec="libx264", audio_codec="aac")

            shutil.rmtree(r'temp\media', ignore_errors=True)
            shutil.rmtree(r'temp\audio', ignore_errors=True)

        st.video(r"temp\final_video.mp4")
